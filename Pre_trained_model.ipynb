{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+UkOKOg+ByeEpxiy340+m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sAI-2025/AI-assisted-Plant-Disease-Detection-and-Management-System-for-Sustainable-Agriculture/blob/main/Pre_trained_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8xlbroja9mr"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "pt_file_path = '/content/yolov5s.pt'\n",
        "export_script_path = '/content/yolov5/export.py'\n",
        "output_weights_path = '/content/Weights'\n",
        "\n",
        "# Load the pretrained PyTorch model\n",
        "model = torch.load(pt_file_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Save the model in a format suitable for export\n",
        "torch.save(model.state_dict(), 'temp.pt')\n",
        "\n",
        "# Run the export script\n",
        "os.system(f'python {export_script_path} --weights temp.pt --img 640 --batch 1')\n",
        "\n",
        "# Rename the exported weights file to .weights\n",
        "os.rename('runs/hub/exp/weights/best.pt', output_weights_path)\n",
        "\n",
        "# Remove the temporary .pt file\n",
        "os.remove('temp.pt')\n",
        "\n",
        "print(f\"Converted .pt file to .weights: {output_weights_path}\")\n"
      ],
      "metadata": {
        "id": "Y93HqEMPbFk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M40UaZXgdF8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yolov5"
      ],
      "metadata": {
        "id": "tLWZbZoV3S9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import yolov5\n",
        "import torch\n",
        "\n",
        "class_names = [\n",
        "    \"Person\", \"Bicycle\", \"Car\", \"Motorcycle\", \"Airplane\", \"Bus\", \"Train\", \"Truck\", \"Boat\",\n",
        "    \"Traffic light\", \"Fire hydrant\", \"Stop sign\", \"Parking meter\", \"Bench\", \"Bird\", \"Cat\",\n",
        "    \"Dog\", \"Horse\", \"Sheep\", \"Cow\", \"Elephant\", \"Bear\", \"Zebra\", \"Giraffe\", \"Backpack\",\n",
        "    \"Umbrella\", \"Handbag\", \"Tie\", \"Suitcase\", \"Frisbee\", \"Skis\", \"Snowboard\", \"Sports ball\",\n",
        "    \"Kite\", \"Baseball bat\", \"Baseball glove\", \"Skateboard\", \"Surfboard\", \"Tennis racket\",\n",
        "    \"Bottle\", \"Wine glass\", \"Cup\", \"Fork\", \"Knife\", \"Spoon\", \"Bowl\", \"Banana\", \"Apple\",\n",
        "    \"Sandwich\", \"Orange\", \"Broccoli\", \"Carrot\", \"Hot dog\", \"Pizza\", \"Donut\", \"Cake\", \"Chair\",\n",
        "    \"Couch\", \"Potted plant\", \"Bed\", \"Dining table\", \"Toilet\", \"TV\", \"Laptop\", \"Mouse\",\n",
        "    \"Remote\", \"Keyboard\", \"Cell phone\", \"Microwave\", \"Oven\", \"Toaster\", \"Sink\", \"Refrigerator\",\n",
        "    \"Book\", \"Clock\", \"Vase\", \"Scissors\", \"Teddy bear\", \"Hair drier\", \"Toothbrush\"]\n",
        "\n",
        "model = yolov5.load('/content/yolov5s.pt')\n",
        "\n",
        "model.conf = 0.75  # NMS confidence threshold\n",
        "model.iou = 0.46  # NMS IoU threshold\n",
        "model.agnostic = False  # NMS class-agnostic\n",
        "model.multi_label = False  # NMS multiple labels per box\n",
        "model.max_det = 1000  # maximum number of detections\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(cv2.CAP_PROP_FPS,1)\n",
        "\n",
        "def draw_boxes(image, boxes, categories, color=(0, 255, 0)):\n",
        "    for i in range(len(boxes)):\n",
        "        x1, y1, x2, y2 = map(int, boxes[i])  # Convert tensor values to integers\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, class_names[int(categories[i])], (x1, y1-2), cv2.FONT_HERSHEY_PLAIN, 0.2, color, 1)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "qdlxfi-a3Ter"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(\"/content/test.mp4\")"
      ],
      "metadata": {
        "id": "WoCXg0xM8Lza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    h, w, _ = frame.shape\n",
        "    results = model(frame)\n",
        "    predictions = results.pred[0]\n",
        "    boxes = predictions[:, :4].cpu().numpy()  # Convert tensor to numpy array\n",
        "    categories = predictions[:, 5].cpu().numpy().astype(int)\n",
        "    print(categories)\n",
        "    # Draw bounding boxes on image\n",
        "    image_with_boxes = draw_boxes(frame, boxes, categories)\n",
        "    cv2.imshow('frame', image_with_boxes)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "FFroGGib3_wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = '/content/test.mp4'\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# Get video properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_video_path = '/content/OUt/output_video.avi'\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Process each frame and write to output video\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    processed_frame = model(frame)\n",
        "    out.write(processed_frame)\n",
        "\n",
        "    cv2.imshow('Processed Frame', processed_frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release everything if job is finished\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "MhObzIuF464F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7V0mIsHb47PQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}